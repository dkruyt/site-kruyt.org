<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>influxdb on Dennis Kruyt</title>
    <link>https://kruyt.org/categories/influxdb/</link>
    <description>Recent content in influxdb on Dennis Kruyt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2019 06:44:10 +0000</lastBuildDate><atom:link href="https://kruyt.org/categories/influxdb/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fortinet FortiADC in Grafana</title>
      <link>https://kruyt.org/fortinet-fortiadc-in-grafana/</link>
      <pubDate>Wed, 21 Aug 2019 06:44:10 +0000</pubDate>
      
      <guid>https://kruyt.org/fortinet-fortiadc-in-grafana/</guid>
      <description>FortiADC is is a application delivery controllers (loadbalancer). The devices metrics are availalbe via SNMP. So it&amp;rsquo;s quite easy to collect those and display them in Grafana.
Pre Install Make sure you have installed InfluxDB as the time-series database Telegraf as collector first. Optional you can also include the FortiADC logs when they are in elasticsearch. I use the Greylog sollution for this.
Quick Start Get the latest files, at my GitHub page</description>
    </item>
    
    <item>
      <title>Docsis stats from ARRIS Ziggo modem</title>
      <link>https://kruyt.org/statistics-from-arris-ziggo-cable-modem/</link>
      <pubDate>Fri, 16 Aug 2019 14:53:00 +0000</pubDate>
      
      <guid>https://kruyt.org/statistics-from-arris-ziggo-cable-modem/</guid>
      <description>I have at home a Ziggo cable internet connection. The modem that Ziggo provides is a Arris modem. I have this modem in bridge mode because I have my own router. But I like to get some DOCSIS statistics from this modem. The modem provide these via a kind of web snmp output, but this is not very useful.
  Ziggo Connect box
  To parse this output into something more readable I create a crude oneliner script.</description>
    </item>
    
    <item>
      <title>Solis Ginlong Inverter Statistics Scraper</title>
      <link>https://kruyt.org/ginlong-scraper/</link>
      <pubDate>Mon, 13 May 2019 19:07:58 +0000</pubDate>
      
      <guid>https://kruyt.org/ginlong-scraper/</guid>
      <description>I have a Solis 5K-G Single Phase Inverter with a Ginlong LAN stick. This stick logs statistics of this inverter every 5 minutes to the Ginlong monitoring pages.
  Ginlong Solis Inverter
  I want use those statistics on the Ginlong site for my own analyses en domotica. To get those statistics to my own systems I created a python script that scrapes PV and inverter statistics from the Ginlong monitor pages every 5 min.</description>
    </item>
    
    <item>
      <title>Huawei FAT WLAN Access Points in Grafana</title>
      <link>https://kruyt.org/huawei-fat-wlan-access-points-in-grafana/</link>
      <pubDate>Thu, 11 Jan 2018 22:20:20 +0000</pubDate>
      
      <guid>https://kruyt.org/huawei-fat-wlan-access-points-in-grafana/</guid>
      <description>With Huawei Enterprise Access points you have different firmware versions for different deployment scenarios. A FIT version for when you have an Wireless Access Controller (AC). This AC will managed all your AP and you have metrics available from within the AC. Huawei also offers a FAT version of the firmware for the AP. This is an standalone verion and there is no central management and overview of your AP&amp;rsquo;s with the FAT version.</description>
    </item>
    
    <item>
      <title>Huawei Dorado all flash metrics in Grafana</title>
      <link>https://kruyt.org/huawei-dorado-all-flash-metrics-in-grafana/</link>
      <pubDate>Thu, 11 Jan 2018 21:51:48 +0000</pubDate>
      
      <guid>https://kruyt.org/huawei-dorado-all-flash-metrics-in-grafana/</guid>
      <description>Recently I got my hands on a nice all flash storage from Huawei, the Dorado 5000. Off course I wanted to see if my Grafana dashboard I created for the Huawei Oceanstor series was also working on the Dorado, most is working, but some mibs are different and not all performance metrics that are availble on the Oceanstor are on the Dorado. So I adjusted the Telegraf and Grafana dashboard to work correclty with the Dorado.</description>
    </item>
    
    <item>
      <title>LizardFS in Grafana</title>
      <link>https://kruyt.org/lizardfs-in-grafana/</link>
      <pubDate>Mon, 14 Aug 2017 19:59:32 +0000</pubDate>
      
      <guid>https://kruyt.org/lizardfs-in-grafana/</guid>
      <description>This plugin/script for Telegraf will collect the metrics from LizardFS and stores it into InfluxDB, then you can view your metrics in Grafana on a templated dashboard.</description>
    </item>
    
    <item>
      <title>Huawei OceanStor metrics in Grafana</title>
      <link>https://kruyt.org/oceanstor_grafana/</link>
      <pubDate>Sat, 22 Jul 2017 19:27:02 +0000</pubDate>
      
      <guid>https://kruyt.org/oceanstor_grafana/</guid>
      <description>I manage a couple of storages at work. I got a few Huawei OceanStor storages. v2 as wel v3 storages. There is some commercial tooling from Huawei available to gather metrics, but that didn&amp;rsquo;t fit my needs. I found out that all or almost all metrics that I need are available via SNMP. So it was not hard to setup a Grafana dashboard with all metrics.
Pre install Make sure you have installed InfluxDB as the time-series database Telegraf as the collector first.</description>
    </item>
    
    <item>
      <title>zswap metrics with Telegraf</title>
      <link>https://kruyt.org/telegraf-zswap/</link>
      <pubDate>Wed, 19 Jul 2017 20:04:51 +0000</pubDate>
      
      <guid>https://kruyt.org/telegraf-zswap/</guid>
      <description>A couple of weeks ago I discover zswap.
 zswap is a Linux kernel feature that provides a compressed write-back cache for swapped pages, as a form of virtual memory compression. Instead of moving memory pages to a swap device when they are to be swapped out, zswap performs their compression and then stores them into a memory pool dynamically allocated in the system RAM. Later writeback to the actual swap device is deferred or even completely avoided, resulting in a significantly reduced I/O for Linux systems that require swapping; the tradeoff is the need for additional CPU cycles to perform the compression.</description>
    </item>
    
  </channel>
</rss>
